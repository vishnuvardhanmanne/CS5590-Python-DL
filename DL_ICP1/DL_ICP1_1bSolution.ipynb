{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_ICP1_1bSolution.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNAinKKWNWV+PNJfmEQ//6V"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"v6C9J_Q0rFCQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"33cf5791-accd-427a-9ee9-a9df5fd78f11","executionInfo":{"status":"ok","timestamp":1584904595079,"user_tz":300,"elapsed":21706,"user":{"displayName":"Manne Vishnu vardhan reddy","photoUrl":"","userId":"18030407940460323927"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-SGwtsrTrO7V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"c5a4b223-0ff9-425e-f803-ff887d06c24e","executionInfo":{"status":"ok","timestamp":1584904705998,"user_tz":300,"elapsed":8943,"user":{"displayName":"Manne Vishnu vardhan reddy","photoUrl":"","userId":"18030407940460323927"}}},"source":["import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","dataset = pd.read_csv(\"drive/My Drive/DL_ICP1/breastcancer.csv\").values\n","from sklearn import preprocessing\n","pre_process = preprocessing.LabelEncoder()\n","pre_process.fit(dataset[:,1])\n","dataset[:,1] = pre_process.transform(dataset[:,1])\n","mapping = {'M': 1, 'B': 2}\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","print (sc.fit(dataset))\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,2:31], dataset[:,1],test_size=0.25, random_state=87)\n","np.random.seed(42)\n","my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(50, input_dim=29, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["StandardScaler(copy=True, with_mean=True, with_std=True)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:765: RuntimeWarning: invalid value encountered in true_divide\n","  updated_mean = (last_sum + new_sum) / updated_sample_count\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py:706: RuntimeWarning: Degrees of freedom <= 0 for slice.\n","  result = op(x, *args, **kwargs)\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","426/426 [==============================] - 1s 1ms/step - loss: 6.3682 - acc: 0.5704\n","Epoch 2/100\n","426/426 [==============================] - 0s 50us/step - loss: 6.1295 - acc: 0.6197\n","Epoch 3/100\n","426/426 [==============================] - 0s 51us/step - loss: 6.1295 - acc: 0.6197\n","Epoch 4/100\n","426/426 [==============================] - 0s 46us/step - loss: 6.1295 - acc: 0.6197\n","Epoch 5/100\n","426/426 [==============================] - 0s 47us/step - loss: 6.1295 - acc: 0.6197\n","Epoch 6/100\n","426/426 [==============================] - 0s 42us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 7/100\n","426/426 [==============================] - 0s 50us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 8/100\n","426/426 [==============================] - 0s 46us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 9/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 10/100\n","426/426 [==============================] - 0s 52us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 11/100\n","426/426 [==============================] - 0s 60us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 12/100\n","426/426 [==============================] - 0s 56us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 13/100\n","426/426 [==============================] - 0s 58us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 14/100\n","426/426 [==============================] - 0s 52us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 15/100\n","426/426 [==============================] - 0s 69us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 16/100\n","426/426 [==============================] - 0s 53us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 17/100\n","426/426 [==============================] - 0s 43us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 18/100\n","426/426 [==============================] - 0s 60us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 19/100\n","426/426 [==============================] - 0s 46us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 20/100\n","426/426 [==============================] - 0s 64us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 21/100\n","426/426 [==============================] - 0s 55us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 22/100\n","426/426 [==============================] - 0s 58us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 23/100\n","426/426 [==============================] - 0s 53us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 24/100\n","426/426 [==============================] - 0s 60us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 25/100\n","426/426 [==============================] - 0s 57us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 26/100\n","426/426 [==============================] - 0s 55us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 27/100\n","426/426 [==============================] - 0s 58us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 28/100\n","426/426 [==============================] - 0s 56us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 29/100\n","426/426 [==============================] - 0s 46us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 30/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 31/100\n","426/426 [==============================] - 0s 44us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 32/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 33/100\n","426/426 [==============================] - 0s 49us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 34/100\n","426/426 [==============================] - 0s 46us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 35/100\n","426/426 [==============================] - 0s 46us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 36/100\n","426/426 [==============================] - 0s 52us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 37/100\n","426/426 [==============================] - 0s 69us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 38/100\n","426/426 [==============================] - 0s 49us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 39/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 40/100\n","426/426 [==============================] - 0s 52us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 41/100\n","426/426 [==============================] - 0s 55us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 42/100\n","426/426 [==============================] - 0s 50us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 43/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 44/100\n","426/426 [==============================] - 0s 51us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 45/100\n","426/426 [==============================] - 0s 62us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 46/100\n","426/426 [==============================] - 0s 46us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 47/100\n","426/426 [==============================] - 0s 49us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 48/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 49/100\n","426/426 [==============================] - 0s 47us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 50/100\n","426/426 [==============================] - 0s 44us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 51/100\n","426/426 [==============================] - 0s 51us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 52/100\n","426/426 [==============================] - 0s 42us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 53/100\n","426/426 [==============================] - 0s 49us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 54/100\n","426/426 [==============================] - 0s 59us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 55/100\n","426/426 [==============================] - 0s 64us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 56/100\n","426/426 [==============================] - 0s 57us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 57/100\n","426/426 [==============================] - 0s 59us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 58/100\n","426/426 [==============================] - 0s 59us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 59/100\n","426/426 [==============================] - 0s 61us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 60/100\n","426/426 [==============================] - 0s 58us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 61/100\n","426/426 [==============================] - 0s 62us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 62/100\n","426/426 [==============================] - 0s 51us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 63/100\n","426/426 [==============================] - 0s 50us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 64/100\n","426/426 [==============================] - 0s 56us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 65/100\n","426/426 [==============================] - 0s 51us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 66/100\n","426/426 [==============================] - 0s 49us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 67/100\n","426/426 [==============================] - 0s 52us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 68/100\n","426/426 [==============================] - 0s 52us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 69/100\n","426/426 [==============================] - 0s 54us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 70/100\n","426/426 [==============================] - 0s 53us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 71/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 72/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 73/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 74/100\n","426/426 [==============================] - 0s 51us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 75/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 76/100\n","426/426 [==============================] - 0s 47us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 77/100\n","426/426 [==============================] - 0s 49us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 78/100\n","426/426 [==============================] - 0s 57us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 79/100\n","426/426 [==============================] - 0s 43us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 80/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 81/100\n","426/426 [==============================] - 0s 50us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 82/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 83/100\n","426/426 [==============================] - 0s 41us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 84/100\n","426/426 [==============================] - 0s 53us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 85/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 86/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 87/100\n","426/426 [==============================] - 0s 53us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 88/100\n","426/426 [==============================] - 0s 54us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 89/100\n","426/426 [==============================] - 0s 53us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 90/100\n","426/426 [==============================] - 0s 44us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 91/100\n","426/426 [==============================] - 0s 47us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 92/100\n","426/426 [==============================] - 0s 57us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 93/100\n","426/426 [==============================] - 0s 47us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 94/100\n","426/426 [==============================] - 0s 43us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 95/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 96/100\n","426/426 [==============================] - 0s 45us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 97/100\n","426/426 [==============================] - 0s 53us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 98/100\n","426/426 [==============================] - 0s 47us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 99/100\n","426/426 [==============================] - 0s 43us/step - loss: 6.1294 - acc: 0.6197\n","Epoch 100/100\n","426/426 [==============================] - 0s 48us/step - loss: 6.1294 - acc: 0.6197\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"446S3C_sro40","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"c695371e-b2cd-4227-cdaf-bf7e36f5b092","executionInfo":{"status":"ok","timestamp":1584904714179,"user_tz":300,"elapsed":434,"user":{"displayName":"Manne Vishnu vardhan reddy","photoUrl":"","userId":"18030407940460323927"}}},"source":["print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 50)                1500      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 51        \n","=================================================================\n","Total params: 1,551\n","Trainable params: 1,551\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","143/143 [==============================] - 0s 296us/step\n","[5.635697721601366, 0.6503496532673603]\n"],"name":"stdout"}]}]}