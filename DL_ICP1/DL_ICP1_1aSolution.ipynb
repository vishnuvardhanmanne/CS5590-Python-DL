{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_ICP1_1aSolution.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMwmyecp790bBVQ+NVjWXXI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"KMhB0AXep81P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"b3f47c77-18d4-4a2c-cf6b-8ee43dca5a59","executionInfo":{"status":"ok","timestamp":1584904312763,"user_tz":300,"elapsed":24773,"user":{"displayName":"Manne Vishnu vardhan reddy","photoUrl":"","userId":"18030407940460323927"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qZFKayk6qJ6r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a2de5cfa-4a10-407e-e765-3b98cd159745","executionInfo":{"status":"ok","timestamp":1584904449598,"user_tz":300,"elapsed":4565,"user":{"displayName":"Manne Vishnu vardhan reddy","photoUrl":"","userId":"18030407940460323927"}}},"source":["import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","dataset = pd.read_csv(\"drive/My Drive/DL_ICP1/diabetes.csv\", header=None).values\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],test_size=0.25, random_state=87)\n","np.random.seed(42)\n","my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(21, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","576/576 [==============================] - 1s 1ms/step - loss: 4.2083 - acc: 0.5017\n","Epoch 2/100\n","576/576 [==============================] - 0s 43us/step - loss: 3.0921 - acc: 0.5694\n","Epoch 3/100\n","576/576 [==============================] - 0s 45us/step - loss: 2.4914 - acc: 0.5885\n","Epoch 4/100\n","576/576 [==============================] - 0s 49us/step - loss: 2.2871 - acc: 0.5920\n","Epoch 5/100\n","576/576 [==============================] - 0s 51us/step - loss: 2.0492 - acc: 0.6111\n","Epoch 6/100\n","576/576 [==============================] - 0s 48us/step - loss: 1.8007 - acc: 0.6146\n","Epoch 7/100\n","576/576 [==============================] - 0s 42us/step - loss: 1.6036 - acc: 0.6285\n","Epoch 8/100\n","576/576 [==============================] - 0s 52us/step - loss: 1.5015 - acc: 0.6111\n","Epoch 9/100\n","576/576 [==============================] - 0s 45us/step - loss: 1.3631 - acc: 0.6076\n","Epoch 10/100\n","576/576 [==============================] - 0s 46us/step - loss: 1.1929 - acc: 0.6632\n","Epoch 11/100\n","576/576 [==============================] - 0s 43us/step - loss: 1.0594 - acc: 0.6649\n","Epoch 12/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.9960 - acc: 0.6493\n","Epoch 13/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.9653 - acc: 0.6562\n","Epoch 14/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.8008 - acc: 0.6562\n","Epoch 15/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.7523 - acc: 0.6562\n","Epoch 16/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.7240 - acc: 0.6736\n","Epoch 17/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.6935 - acc: 0.6736\n","Epoch 18/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.7211 - acc: 0.6632\n","Epoch 19/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.7390 - acc: 0.6615\n","Epoch 20/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.7503 - acc: 0.6372\n","Epoch 21/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.7366 - acc: 0.6528\n","Epoch 22/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6585 - acc: 0.6667\n","Epoch 23/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6487 - acc: 0.6615\n","Epoch 24/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.6647 - acc: 0.6840\n","Epoch 25/100\n","576/576 [==============================] - 0s 57us/step - loss: 0.6340 - acc: 0.6910\n","Epoch 26/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.6543 - acc: 0.6806\n","Epoch 27/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6182 - acc: 0.6771\n","Epoch 28/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.6234 - acc: 0.6910\n","Epoch 29/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6117 - acc: 0.6684\n","Epoch 30/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6061 - acc: 0.6840\n","Epoch 31/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.6055 - acc: 0.6806\n","Epoch 32/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5987 - acc: 0.6875\n","Epoch 33/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6200 - acc: 0.6753\n","Epoch 34/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.6167 - acc: 0.6979\n","Epoch 35/100\n","576/576 [==============================] - 0s 57us/step - loss: 0.6045 - acc: 0.6771\n","Epoch 36/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.6104 - acc: 0.7031\n","Epoch 37/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.6421 - acc: 0.6649\n","Epoch 38/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5985 - acc: 0.7014\n","Epoch 39/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5958 - acc: 0.7049\n","Epoch 40/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5777 - acc: 0.6840\n","Epoch 41/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.6179 - acc: 0.6823\n","Epoch 42/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.6159 - acc: 0.7014\n","Epoch 43/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5969 - acc: 0.6962\n","Epoch 44/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5882 - acc: 0.7118\n","Epoch 45/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5825 - acc: 0.6944\n","Epoch 46/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5907 - acc: 0.7031\n","Epoch 47/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5700 - acc: 0.6997\n","Epoch 48/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6151 - acc: 0.6806\n","Epoch 49/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5819 - acc: 0.7066\n","Epoch 50/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5738 - acc: 0.7170\n","Epoch 51/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5956 - acc: 0.6979\n","Epoch 52/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5570 - acc: 0.7170\n","Epoch 53/100\n","576/576 [==============================] - 0s 57us/step - loss: 0.5912 - acc: 0.6997\n","Epoch 54/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.6121 - acc: 0.6858\n","Epoch 55/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5804 - acc: 0.7049\n","Epoch 56/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5777 - acc: 0.7031\n","Epoch 57/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5729 - acc: 0.7049\n","Epoch 58/100\n","576/576 [==============================] - 0s 63us/step - loss: 0.6056 - acc: 0.7135\n","Epoch 59/100\n","576/576 [==============================] - 0s 64us/step - loss: 0.5712 - acc: 0.6979\n","Epoch 60/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.5568 - acc: 0.7135\n","Epoch 61/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5882 - acc: 0.6927\n","Epoch 62/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5852 - acc: 0.6944\n","Epoch 63/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.5644 - acc: 0.7240\n","Epoch 64/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.5639 - acc: 0.7274\n","Epoch 65/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.5682 - acc: 0.7188\n","Epoch 66/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5516 - acc: 0.7170\n","Epoch 67/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5743 - acc: 0.6997\n","Epoch 68/100\n","576/576 [==============================] - 0s 62us/step - loss: 0.5561 - acc: 0.7274\n","Epoch 69/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5445 - acc: 0.7309\n","Epoch 70/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5639 - acc: 0.6962\n","Epoch 71/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5544 - acc: 0.7205\n","Epoch 72/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5506 - acc: 0.7326\n","Epoch 73/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5489 - acc: 0.7240\n","Epoch 74/100\n","576/576 [==============================] - 0s 58us/step - loss: 0.5465 - acc: 0.7396\n","Epoch 75/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5693 - acc: 0.7222\n","Epoch 76/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5894 - acc: 0.7101\n","Epoch 77/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5410 - acc: 0.7222\n","Epoch 78/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5835 - acc: 0.7222\n","Epoch 79/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5549 - acc: 0.7309\n","Epoch 80/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5413 - acc: 0.7396\n","Epoch 81/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.5653 - acc: 0.7205\n","Epoch 82/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.5480 - acc: 0.7326\n","Epoch 83/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5259 - acc: 0.7361\n","Epoch 84/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5449 - acc: 0.7188\n","Epoch 85/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5810 - acc: 0.6944\n","Epoch 86/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5763 - acc: 0.7135\n","Epoch 87/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5306 - acc: 0.7465\n","Epoch 88/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5682 - acc: 0.7083\n","Epoch 89/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5494 - acc: 0.7240\n","Epoch 90/100\n","576/576 [==============================] - 0s 71us/step - loss: 0.5532 - acc: 0.7240\n","Epoch 91/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5726 - acc: 0.7118\n","Epoch 92/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5260 - acc: 0.7448\n","Epoch 93/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5230 - acc: 0.7465\n","Epoch 94/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5553 - acc: 0.7153\n","Epoch 95/100\n","576/576 [==============================] - 0s 70us/step - loss: 0.5762 - acc: 0.6997\n","Epoch 96/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.5548 - acc: 0.7326\n","Epoch 97/100\n","576/576 [==============================] - 0s 66us/step - loss: 0.5608 - acc: 0.7188\n","Epoch 98/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.5321 - acc: 0.7483\n","Epoch 99/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5280 - acc: 0.7413\n","Epoch 100/100\n","576/576 [==============================] - 0s 59us/step - loss: 0.5204 - acc: 0.7396\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bOAh4ia1qreG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":269},"outputId":"6c6b88f8-3688-4f95-800e-940bd4b58d20","executionInfo":{"status":"ok","timestamp":1584904461557,"user_tz":300,"elapsed":350,"user":{"displayName":"Manne Vishnu vardhan reddy","photoUrl":"","userId":"18030407940460323927"}}},"source":["print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 21)                189       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 22        \n","=================================================================\n","Total params: 211\n","Trainable params: 211\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","192/192 [==============================] - 0s 189us/step\n","[0.6306143005688986, 0.6770833333333334]\n"],"name":"stdout"}]}]}